{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK TO PREDICT CARDIOVASCULAR DISEASES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### *To see our info page (about cardiovascular diseases and info about us), you could visit : https://mailchi.mp/dd56c857ba2e/heartaid*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import seaborn as sns             # visualizations\n",
    "import matplotlib.pyplot as plt   # visualizations\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "id                                                                          \n",
       "0   18393       2     168    62.0    110     80            1     1      0   \n",
       "1   20228       1     156    85.0    140     90            3     1      0   \n",
       "2   18857       1     165    64.0    130     70            3     1      0   \n",
       "3   17623       2     169    82.0    150    100            1     1      0   \n",
       "4   17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "    alco  active  cardio  \n",
       "id                        \n",
       "0      0       1       0  \n",
       "1      0       1       1  \n",
       "2      0       0       1  \n",
       "3      0       1       1  \n",
       "4      0       0       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"cardio_train.csv\")\n",
    "df=data.from_csv(\"cardio_train.csv\", header=0, sep=\";\")\n",
    "dfcol=df.columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the targets are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"cardio\",\"height\"]].groupby(\"cardio\").count()\n",
    "sns.countplot(x=\"cardio\", data=df, palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transform (Scaling to avoid outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "scaler=preprocessing.MinMaxScaler()\n",
    "dfscale=scaler.fit_transform(df)\n",
    "dfscale2=pd.DataFrame(dfscale, columns=dfcol)\n",
    "dfscale2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf=dfscale2.iloc[:,0:11]\n",
    "#xdf[\"gender\"]=np.where(xdf[\"gender\"]==1,\"0\",\"1\") #Cambiar el 2 por 1, el 1 por 0 (por orden)\n",
    "#Aca vendria un posible drop de variables xdf=xdf.drop([\"gender\",\"gluc\"], axis=1)\n",
    "ydf=dfscale2.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training, x_testing, y_training, y_testing = train_test_split(xdf, ydf, test_size = 0.2, random_state=123, stratify=ydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dropout\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=11, activation='softsign', kernel_constraint=maxnorm(2)))\n",
    "#model.add(Dropout(0))\n",
    "model.add(Dense(5, activation='softsign'))\n",
    "#model.add(Dropout(0))\n",
    "model.add(Dense(3, activation='softsign'))\n",
    "#model.add(Dropout(0))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_training, y_training, epochs=50, batch_size=50, verbose=0)\n",
    "score = model.evaluate(x_training, y_training)\n",
    "print(\"\\n Training Accuracy:\", score[1])\n",
    "score = model.evaluate(x_testing, y_testing)\n",
    "print(\"\\n Testing Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Initial Accuracy**= 0.6465 \n",
    "* **Final aprox Accuracy**= 0.68-0.719"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=model.predict(x_testing)\n",
    "res\n",
    "resdf=pd.DataFrame(res, index=x_testing.index)\n",
    "resdf.columns=[\"Pr\"]\n",
    "resdf[\"ID\"]=range(14000)\n",
    "resdf[\"y\"]=np.where(resdf[\"Pr\"]>=0.5,\"1\", \"0\")\n",
    "resdf\n",
    "prediction=resdf.drop([\"Pr\",\"ID\"], axis=1)\n",
    "predictionarray=prediction.astype(np.float)\n",
    "sns.distplot(resdf[\"Pr\"],  color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many 1's and 0's predict the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=resdf[['ID','y']].groupby('y').count()\n",
    "c1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many 1's and 0's are in the test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testingdf=pd.DataFrame(y_testing, index=y_testing.index)\n",
    "y_testingdf[\"ID\"]=range(14000)\n",
    "y_test=y_testingdf.drop([\"ID\"], axis=1)\n",
    "c2=y_testingdf[['ID','cardio']].groupby('cardio').count()\n",
    "c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test.values, predictionarray)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy=cm[0,0]/(cm[0,0]+cm[1,0])\n",
    "print(\"The accuracy of the model is: \"+ str(Accuracy*100) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that of all the people with Cardiovascular Disease in the Test-DataBase, the model identify **73% (aprox.)** of the total cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting a single case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSERT DATA#\n",
    "###############################################################################\n",
    "\n",
    "day= 25 # day of bith \n",
    "month= 9 # month of bith (in numbers)\n",
    "year= 1998 # year of bith\n",
    "gender= 1 # 0 for women, 1 for men\n",
    "height= 183 # in cm\n",
    "weight= 89 # in kilograms\n",
    "systolicbloodpressure= 120 # Systolic blood pressure\n",
    "diastolicbloodpressure= 80 # Diastolic blood pressure\n",
    "cholesterol= 1 # 1: normal, 2: above normal, 3: well above normal\n",
    "gluc= 1 # 1: normal, 2: above normal, 3: well above normal\n",
    "smoke= 0 # 1 if you smoke, 0 if not\n",
    "alco= 0 # 1 if you drink alcohol, 0 if not\n",
    "active= 1 # 1 if you do physical activity, 0 if not\n",
    "\n",
    "##############################################################################\n",
    "from datetime import date\n",
    "f_date = date(year,month,day)\n",
    "l_date = date.today()\n",
    "delta = l_date - f_date\n",
    "agedays=delta.days\n",
    "\n",
    "agedayscale=(agedays-df[\"age\"].min())/(df[\"age\"].max()-df[\"age\"].min())\n",
    "heightscale=(height-df[\"height\"].min())/(df[\"height\"].max()-df[\"height\"].min())\n",
    "weightscale=(weight-df[\"weight\"].min())/(df[\"weight\"].max()-df[\"weight\"].min())\n",
    "sbpscale=(systolicbloodpressure-df[\"ap_hi\"].min())/(df[\"ap_hi\"].max()-df[\"ap_hi\"].min())\n",
    "dbpscale=(diastolicbloodpressure-df[\"ap_lo\"].min())/(df[\"ap_lo\"].max()-df[\"ap_lo\"].min())\n",
    "cholesterolscale=(cholesterol-df[\"cholesterol\"].min())/(df[\"cholesterol\"].max()-df[\"cholesterol\"].min())\n",
    "glucscale=(gluc-df[\"gluc\"].min())/(df[\"gluc\"].max()-df[\"gluc\"].min())\n",
    "\n",
    "single=np.array([agedayscale, gender, heightscale, weightscale, sbpscale, dbpscale, cholesterolscale, glucscale, smoke, alco, active ])\n",
    "singledf=pd.DataFrame(single)\n",
    "final=singledf.transpose()\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finalres=model.predict(final)\n",
    "finalres\n",
    "print(\"The probability of having or to have a Cardiovascular Disease is: \"+ str(round(finalres[0,0]*100,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "#model.save_weights(\"weights.hdf5\")\n",
    "json_string = model.to_json()\n",
    "modeltopredict = model_from_json(json_string)\n",
    "modeltopredict.load_weights(\"../input/weights-nn/weights.hdf5\", by_name=False)\n",
    "\n",
    "prediction=modeltopredict.predict(final)\n",
    "\n",
    "if prediction[0,0]>=0.5:\n",
    "    print(\"The probability of having or to have a Cardiovascular Disease is: \"+ str(round(prediction[0,0]*100,2)) + \"%\")\n",
    "    print(\"You must visit a doctor to check it :(\")\n",
    "elif prediction[0,0]<0.5 and prediction[0,0]>=0.3:\n",
    "    print(\"The probability of having or to have a Cardiovascular Disease is: \"+ str(round(prediction[0,0]*100,2)) + \"%\")\n",
    "    print(\"Probably you are healthy :/ \")\n",
    "else:\n",
    "    print(\"The probability of having or to have a Cardiovascular Disease is: \"+ str(round(prediction[0,0]*100,2)) + \"%\")\n",
    "    print(\"You are healthy :) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters to look up for the best NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Size and Epochs\n",
    "\n",
    "In the final kernel, this code is not gonna be available 'cause it takes too much time to run this parts of code.\n",
    "The summary will be written below the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=11, activation='tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(3, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#### create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "#### define the parameters to search in grid search \n",
    "batch_size = [10, 50, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\n",
    "grid_result = grid.fit(x_training, y_training)\n",
    "\n",
    "#### summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:** \n",
    "* Best: 0.640893 using {**'batch_size': 50, 'epochs': 50**}\n",
    "* 0.638214 (0.003997) with: {'batch_size': 10, 'epochs': 10}\n",
    "* 0.640446 (0.006447) with: {'batch_size': 10, 'epochs': 50}\n",
    "* 0.613500 (0.060568) with: {'batch_size': 10, 'epochs': 100}\n",
    "* 0.617089 (0.012489) with: {'batch_size': 50, 'epochs': 10}\n",
    "* 0.640893 (0.004402) with: {'batch_size': 50, 'epochs': 50}\n",
    "* 0.640661 (0.003730) with: {'batch_size': 50, 'epochs': 100}\n",
    "* 0.613732 (0.017299) with: {'batch_size': 100, 'epochs': 10}\n",
    "* 0.635268 (0.005980) with: {'batch_size': 100, 'epochs': 50}\n",
    "* 0.639482 (0.007552) with: {'batch_size': 100, 'epochs': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Algorithm\n",
    "\n",
    "In the final kernel, this code is not gonna be available 'cause it takes too much time to run this parts of code.\n",
    "The summary will be written below the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function to create model\n",
    "def create_model(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=11, activation='tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(3, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#### create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=0)\n",
    "\n",
    "#### define the parameters to search in grid search \n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\n",
    "grid_result = grid.fit(x_training, y_training)\n",
    "\n",
    "#### summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:** \n",
    "* Best: 0.708232 using {**'optimizer': 'Nadam'**}\n",
    "* 0.639339 (0.003833) with: {'optimizer': 'SGD'}\n",
    "* 0.685446 (0.014199) with: {'optimizer': 'RMSprop'}\n",
    "* 0.644750 (0.004682) with: {'optimizer': 'Adagrad'}\n",
    "* 0.664732 (0.011830) with: {'optimizer': 'Adadelta'}\n",
    "* 0.676821 (0.017248) with: {'optimizer': 'Adam'}\n",
    "* 0.653625 (0.003463) with: {'optimizer': 'Adamax'}\n",
    "* 0.708232 (0.010960) with: {'optimizer': 'Nadam'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization of SGD algorithm (Learnig Rate and Momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function to create model\n",
    "def create_model(learn_rate=0.01, momentum=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=11, activation='tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(3, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#### create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=0)\n",
    "\n",
    "#### define the parameters to search in grid search \n",
    "learn_rate = [0.01, 0.1, 0.2]\n",
    "momentum = [0.2, 0.6, 0.9]\n",
    "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\n",
    "grid_result = grid.fit(x_training, y_training)\n",
    "\n",
    "#### summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:** \n",
    "* Best: 0.642571 using {**'learn_rate': 0.01, 'momentum': 0.2**}\n",
    "* 0.642571 (0.004326) with: {'learn_rate': 0.01, 'momentum': 0.2}\n",
    "* 0.642375 (0.003565) with: {'learn_rate': 0.01, 'momentum': 0.6}\n",
    "* 0.641786 (0.005498) with: {'learn_rate': 0.01, 'momentum': 0.9}\n",
    "* 0.586232 (0.069370) with: {'learn_rate': 0.1, 'momentum': 0.2}\n",
    "* 0.642089 (0.004087) with: {'learn_rate': 0.1, 'momentum': 0.6}\n",
    "* 0.638589 (0.006434) with: {'learn_rate': 0.1, 'momentum': 0.9}\n",
    "* 0.498554 (0.005800) with: {'learn_rate': 0.2, 'momentum': 0.2}\n",
    "* 0.587482 (0.071161) with: {'learn_rate': 0.2, 'momentum': 0.6}\n",
    "* 0.594286 (0.058599) with: {'learn_rate': 0.2, 'momentum': 0.9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def create_model(activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=11, activation=activation))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(5, activation=activation))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(3, activation=activation))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer=\"Nadam\", metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#### create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=0)\n",
    "\n",
    "#### define the parameters to search in grid search \n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\n",
    "grid_result = grid.fit(x_training, y_training)\n",
    "\n",
    "#### summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:** \n",
    "* Best: 0.717250 using {**'activation': 'softsign'**}\n",
    "* 0.649786 (0.005472) with: {'activation': 'softmax'}\n",
    "* 0.649464 (0.005333) with: {'activation': 'softplus'}\n",
    "* 0.717250 (0.006675) with: {'activation': 'softsign'}\n",
    "* 0.701964 (0.021487) with: {'activation': 'relu'}\n",
    "* 0.717179 (0.002289) with: {'activation': 'tanh'}\n",
    "* 0.648446 (0.006001) with: {'activation': 'sigmoid'}\n",
    "* 0.651750 (0.004286) with: {'activation': 'hard_sigmoid'}\n",
    "* 0.709232 (0.015933) with: {'activation': 'linear'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Rate and Weight Constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "#### function to create model\n",
    "def create_model(dropout_rate=0.0, weight_constraint=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=11, activation='softsign', kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(5, activation='softsign'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(3, activation='softsign'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#### create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=0)\n",
    "\n",
    "#### define the parameters to search in grid search \n",
    "weight_constraint = [0, 1, 2]\n",
    "dropout_rate = [0.0, 0.1, 0.2]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\n",
    "grid_result = grid.fit(x_training, y_training)\n",
    "\n",
    "#### summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "* Best: 0.701179 using {**'dropout_rate': 0.0, 'weight_constraint': 2**}\n",
    "* 0.500839 (0.005918) with: {'dropout_rate': 0.0, 'weight_constraint': 0}\n",
    "* 0.651839 (0.005446) with: {'dropout_rate': 0.0, 'weight_constraint': 1}\n",
    "* 0.701179 (0.010650) with: {'dropout_rate': 0.0, 'weight_constraint': 2}\n",
    "* 0.500446 (0.005961) with: {'dropout_rate': 0.1, 'weight_constraint': 0}\n",
    "* 0.648250 (0.007944) with: {'dropout_rate': 0.1, 'weight_constraint': 1}\n",
    "* 0.684536 (0.022927) with: {'dropout_rate': 0.1, 'weight_constraint': 2}\n",
    "* 0.500304 (0.005970) with: {'dropout_rate': 0.2, 'weight_constraint': 0}\n",
    "* 0.649732 (0.002889) with: {'dropout_rate': 0.2, 'weight_constraint': 1}\n",
    "* 0.666893 (0.011692) with: {'dropout_rate': 0.2, 'weight_constraint': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of neurons in the first layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def create_model(neurons=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=11, activation='softsign', kernel_constraint=maxnorm(2)))\n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(5, activation='softsign'))\n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(3, activation='softsign'))\n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#### create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=0)\n",
    "\n",
    "#### define the parameters to search in grid search \n",
    "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "param_grid = dict(neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\n",
    "grid_result = grid.fit(x_training, y_training)\n",
    "\n",
    "#### summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "* Best: 0.703107 using {**'neurons': 25**}\n",
    "* 0.683607 (0.003922) with: {'neurons': 1}\n",
    "* 0.700411 (0.003911) with: {'neurons': 5}\n",
    "* 0.694625 (0.009716) with: {'neurons': 10}\n",
    "* 0.699536 (0.009807) with: {'neurons': 15}\n",
    "* 0.698893 (0.013422) with: {'neurons': 20}\n",
    "* 0.703107 (0.014787) with: {'neurons': 25}\n",
    "* 0.688821 (0.026863) with: {'neurons': 30}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
